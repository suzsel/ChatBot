# OREC Document Assistant

This project is a web-based question-answering system for the Oklahoma Real Estate Commission (OREC) Code and Rule Book. It allows users to query regulations, licensing requirements, and procedures, with answers generated by an AI model trained on structured JSON data. The interface displays a chat window for queries and responses, alongside an interactive panel showing document sections. Responses include references to the most relevant section, which is highlighted in the sections panel.

## Project Structure

```
OREC-Document-Assistant/
├── OREC/
│   ├── data.json           # Original JSON file with OREC document data
│   ├── cleaned_document.json  # Cleaned JSON file with essential fields
├── templates/
│   ├── chat.html           # Frontend HTML template for the chat interface
├── clean.py                # Script to clean the original JSON data
├── app.py                  # Main Flask application
├── .env                    # Environment file for OpenAI API key (not tracked)
└── README.md               # Project documentation
```

### File Descriptions

- **`clean.py`**:
  - **Purpose**: Processes the original `OREC/data.json` file to extract essential fields (`chapterNum`, `title` for chapters; `subChapterNum`, `title` for subchapters; `sectionNum`, `title`, `text` for sections) and removes irrelevant metadata (e.g., `_id`, `parentId`).
  - **Output**: Generates `OREC/cleaned_document.json` with a simplified, hierarchical structure suitable for training the search engine.
  - **Usage**: Run `python clean.py` with `OREC/data.json` in the same directory.

- **`app.py`**:
  - **Purpose**: The main Flask application that serves the web interface and handles queries.
  - **Functionality**:
    - Loads `OREC/cleaned_document.json` and trains a FAISS vector store with OpenAI embeddings for semantic search.
    - Uses LangChain and OpenAI's `gpt-3.5-turbo-instruct` model to generate answers based on document content.
    - Logs the cost of each OpenAI API response (e.g., token usage) in the console using `get_openai_callback`.
    - Provides three endpoints:
      - `GET /`: Serves the `chat.html` interface.
      - `GET /api/sections`: Returns the hierarchical document structure for display.
      - `POST /api/query`: Processes user queries, returns answers, and references the most relevant section.
      - `GET /api/health`: Checks system status and initialization.
  - **Dependencies**: Requires `flask`, `flask-cors`, `python-dotenv`, `langchain`, `openai`, `faiss-cpu`.

- **`templates/chat.html`**:
  - **Purpose**: The frontend interface for user interaction.
  - **Features**:
    - A messenger-style chat window on the left:
      - Fixed input box at the bottom for typing queries.
      - User messages displayed on the right (blue bubbles).
      - LLM responses displayed on the left (gray bubbles) with section references below.
    - An interactive sections panel on the right with collapsible chapters, subchapters, and sections.
    - Highlights and scrolls to the referenced section for each query response.
  - **Styling**: Uses Tailwind CSS (via CDN) for responsive design.

- **`OREC/data.json`**:
  - The original JSON file containing the OREC Code and Rule Book data, including chapters, subchapters, sections, and metadata.

- **`OREC/cleaned_document.json`**:
  - The cleaned JSON file generated by `clean.py`, containing only the essential fields (`chapterNum`, `title`, `subchapters` with `subChapterNum`, `title`, and `sections` with `sectionNum`, `title`, `text`) used by the search engine.

## Setup Instructions

1. **Clone the Repository**:
   ```bash
   git clone https://github.com/suzsel/ChatBot.git
   cd ChatBot
   ```

2. **Install Dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

3. **Set Up Environment**:
   - Create a `.env` file in the root directory:
     ```env
     OPENAI_API_KEY=your-openai-api-key-here
     ```
   - Obtain an OpenAI API key from [OpenAI](https://platform.openai.com).

4. **Prepare Data**:
   - Place the original `OREC/data.json` in the `OREC/` directory.
   - Run the cleaning script to generate `OREC/cleaned_document.json`:
     ```bash
     python clean.py
     ```

5. **Run the Application**:
   ```bash
   python app.py
   ```
   - The Flask server will start at `http://localhost:5000`.
   - Open this URL in a web browser to access the chat interface.

6. **Verify Setup**:
   - Check the console logs for initialization messages (e.g., "✅ QA System initialized with X chunks").
   - If initialization fails, ensure `OREC/cleaned_document.json` exists and `OPENAI_API_KEY` is set correctly.
   - The app logs the cost of each OpenAI API response (e.g., token usage) in the console for every query.

## Usage

1. **Access the Interface**:
   - Navigate to `http://localhost:5000`.
   - The left side shows a chat window with a fixed input box at the bottom.
   - The right side displays collapsible chapters, subchapters, and sections from `cleaned_document.json`.

2. **Ask Questions**:
   - Type a question (e.g., "What is the purpose of the Real Estate Commission?") in the input box and press Enter or click Send.
   - User messages appear on the right (blue bubbles).
   - LLM responses appear on the left (gray bubbles) with a reference to the most relevant section (e.g., "Section 605:1-1-1 (Statement of purpose) in Chapter 1, Subchapter 1").
   - The referenced section is highlighted and scrolled into view in the sections panel.

3. **Interact with Sections**:
   - Click chapter, subchapter, or section headers to expand/collapse their content.
   - Section text is displayed in a scrollable box for long content.

## Example Interaction

- **Input**: "What is the purpose of the Real Estate Commission?"
- **Output**:
  ```
  [Right, blue bubble] You: What is the purpose of the Real Estate Commission?
  [Left, gray bubble] The fundamental and primary purpose of the Real Estate Commission is to safeguard public interest...
  [Left, smaller gray text] Reference: Section 605:1-1-1 (Statement of purpose) in Chapter 1, Subchapter 1
  ```
- **Sections Panel**: The section "605:1-1-1: Statement of purpose" is highlighted and scrolled into view.

## Logging

- **Initialization Logs**: `app.py` logs whether the QA system initialized successfully and the number of text chunks loaded.
- **Query Cost Logs**: For each query to `/api/query`, `app.py` logs the OpenAI API cost (e.g., token usage) in the console using `get_openai_callback`. Example:
  ```
  INFO:__main__:Query cost: Tokens: 123 (Prompt: 100, Completion: 23, Total Cost: $0.00123)
  ```
- **Error Logs**: Any errors (e.g., missing JSON file, invalid API key) are logged with details for debugging.
